Infos:
  save_name: Results

Modes:
  # default settings
  train_default: False
  random_time: True
  static_init: True

  vision_based: True

  # observation space
  clean_obs: True
  encode_obs_time: True
  encode_hand_object_dist: True
  zero_object_visual_feature: True

  # running modes
  init_pca_hand: False
  flag_joint_dist: False
  flag_body_dist: True

  # hyper params
  double_update_step: True
  double_iteration_step: False
  double_update_half_iteration_step: False

Models:
  # model design
  pi_hid_sizes: [1024, 1024, 512, 512]
  vf_hid_sizes: [1024, 1024, 512, 512]
  activation: elu # can be elu, relu, selu, crelu, lrelu, tanh, sigmoid
  backbone_type: None
  freeze_backbone: False
  sigmoid_actions: False

Weights:
  # space
  num_action: 22 # default 24
  num_observation: 400

  # init hand pose
  delta_init_qpos_value: -0.1

  # hand to object distances
  right_hand_dist: -1.0
  right_hand_finger_dist: -1.0
  right_hand_joint_dist: 0.0
  right_hand_body_dist: -1.0
  # contact threshold
  max_finger_dist: 0.3
  max_hand_dist: 0.06
  max_goal_dist: 0.05

  # target hand pca rot
  delta_target_hand_pca: 0.0
  # random hand exploration
  right_hand_exploration_dist: 0.0

  # distance to goal
  goal_dist: -0.5
  goal_rew: 1.0
  # move up
  hand_up: 2.0
  # goal bonus
  bonus: 1.0

  # goal_dist in hand_up
  hand_up_goal_dist: 1.0


Distills:
  save_name: universal_policy/vision_based

  # use_object_pcas: True
  # use_dynamic_pcas: True
  
  # hyper_params
  double_update_step: True
  double_iteration_step: False
  double_update_half_iteration_step: False

  # observation space
  zero_object_visual_feature: False
  dynamic_object_visual_feature: True
  object_visual_feature: PN_128_scaled

  # critic MLP sizes 
  vf_hid_sizes: [1024, 1024, 512, 512]

  # use model type
  use_model_type: transformer_encoder


Offlines:
  save_name: universal_policy/vision_based

  # use_object_pcas: True
  # use_dynamic_pcas: True

  # locate trajectory folder
  trajectory_name: results_trajectory_render

  # use transformer_encoder actor
  # transformer encoder
  num_features: 256
  num_layers: 12
  num_heads: 16
  # transformer decoder
  concat_features: True
  decoder_hid_sizes: [1024, 1024, 512, 512]
  decoder_activation: elu

  # use mlp critic 
  vf_hid_sizes: [1024, 1024, 512, 512]
  activation: elu # can be elu, relu, selu, crelu, lrelu, tanh, sigmoid
  learning_rate: 1e-4

  # observation space
  zero_object_visual_feature: False
  dynamic_object_visual_feature: True
  object_visual_feature: PN_128_scaled

  # settings
  sigmoid_actions: False
  use_valid_trajectory: False # Default True, the modified singulation does not have valid flag updated


# interval hand_dofs 0 66
# interval hand_states 66 72
# interval actions 72 94
# interval objects 94 110
# interval object_visual 110 238
# interval times 238 267
# interval hand_objects 267 311
# interval singulation_distances 311 319

# Observation dimensions:
# hand_dofs: torch.Size([32, 48])
# hand_states: torch.Size([32, 6])
# actions: torch.Size([32, 22])
# objects: torch.Size([32, 16])
# object_visual: torch.Size([32, 128])
# times: torch.Size([32, 29])
# hand_objects: torch.Size([32, 21])
# singulation_distances: torch.Size([32, 8])
Obs:
  # observation intervals
  intervals:
    hand_dofs: # 66
    - 0
    - 66 
    hand_states: # 6
    - 66
    - 72
    actions: # 22
    - 72
    - 94
    objects: # 16
    - 94
    - 110
    object_visual: # 128
    - 110
    - 238
    times: # 29
    - 238
    - 267
    hand_objects: # 21
    - 267
    - 288
    singulation_distances: # 8
    - 288
    - 296
    
  # observation names
  names:
  - hand_dofs
  - hand_states
  - actions
  - objects
  - object_visual
  - times
  - hand_objects
  - singulation_distances